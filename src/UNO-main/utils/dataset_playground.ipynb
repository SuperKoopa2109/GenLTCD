{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in c:\\dev\\anaconda3\\lib\\site-packages (0.8.5)\n",
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n",
      "     -------------------------------------- 585.5/585.5 KB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\dev\\anaconda3\\lib\\site-packages (from pytorch_lightning) (1.19.5)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "     -------------------------------------- 140.6/140.6 KB 8.1 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.0.0\n",
      "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: torch>=1.8.* in c:\\dev\\anaconda3\\lib\\site-packages (from pytorch_lightning) (1.10.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\dev\\anaconda3\\lib\\site-packages (from pytorch_lightning) (20.4)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.9.0-py3-none-any.whl (418 kB)\n",
      "     -------------------------------------- 418.2/418.2 KB 8.7 MB/s eta 0:00:00\n",
      "Collecting PyYAML>=5.4\n",
      "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "     -------------------------------------- 155.4/155.4 KB 9.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<=3.20.1 in c:\\dev\\anaconda3\\lib\\site-packages (from pytorch_lightning) (3.19.1)\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>=4.57.0\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 KB ? eta 0:00:00\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\dev\\anaconda3\\lib\\site-packages (from pytorch_lightning) (2.6.0)\n",
      "Requirement already satisfied: requests in c:\\dev\\anaconda3\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.24.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-win_amd64.whl (555 kB)\n",
      "     -------------------------------------- 556.0/556.0 KB 7.0 MB/s eta 0:00:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\dev\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: six in c:\\dev\\anaconda3\\lib\\site-packages (from packaging>=17.0->pytorch_lightning) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\dev\\anaconda3\\lib\\site-packages (from packaging>=17.0->pytorch_lightning) (2.4.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (49.2.0.post20200714)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.41.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.14.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\dev\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
      "Requirement already satisfied: colorama in c:\\dev\\anaconda3\\lib\\site-packages (from tqdm>=4.57.0->pytorch_lightning) (0.4.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\dev\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\dev\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\dev\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\dev\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\dev\\anaconda3\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\anaconda3\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\dev\\anaconda3\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\dev\\anaconda3\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.25.9)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp38-cp38-win_amd64.whl (33 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp38-cp38-win_amd64.whl (122 kB)\n",
      "     -------------------------------------- 122.2/122.2 KB 7.0 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\dev\\anaconda3\\lib\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (19.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\dev\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\dev\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
      "Installing collected packages: typing-extensions, tqdm, PyYAML, pyDeprecate, multidict, fsspec, frozenlist, charset-normalizer, async-timeout, yarl, aiosignal, torchmetrics, aiohttp, pytorch_lightning\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.2\n",
      "    Uninstalling typing-extensions-3.7.4.2:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.47.0\n",
      "    Uninstalling tqdm-4.47.0:\n",
      "      Successfully uninstalled tqdm-4.47.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pytorch-lightning\n",
      "Version: 0.8.5\n",
      "Summary: PyTorch Lightning is the lightweight PyTorch wrapper for ML researchers. Scale your models. Write less boilerplate.\n",
      "Home-page: https://github.com/PyTorchLightning/pytorch-lightning\n",
      "Author: William Falcon et al.\n",
      "Author-email: waf2107@columbia.edu\n",
      "License: Apache-2.0\n",
      "Location: c:\\dev\\anaconda3\\lib\\site-packages\n",
      "Requires: future, numpy, PyYAML, tensorboard, torch, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchtext.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Batch' from 'torchtext.data' (C:\\dev\\anaconda3\\lib\\site-packages\\torchtext\\data\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-580ac0355fc3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mpytorch_lightning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpl\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtransforms\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\dev\\anaconda3\\lib\\site-packages\\pytorch_lightning\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[1;31m# We are not importing the rest of the lightning during the build process, as it may not be compiled yet\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 53\u001B[1;33m     \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLightningModule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_loader\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     54\u001B[0m     \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mCallback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTrainer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\dev\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    337\u001B[0m \"\"\"\n\u001B[0;32m    338\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 339\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecorators\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdata_loader\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    340\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlightning\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLightningModule\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    341\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\dev\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\decorators.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlightning\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLightningModule\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutilities\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mrank_zero_warn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\dev\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_logger\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mlog\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrads\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mGradInformation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhooks\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModelHooks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmemory\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModelSummary\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msaving\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModelIO\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mPRIMITIVE_TYPES\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mALLOWED_CONFIG_TYPES\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\dev\\anaconda3\\lib\\site-packages\\pytorch_lightning\\core\\hooks.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModule\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mOptimizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutilities\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmove_data_to_device\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mNATIVE_AMP_AVALAIBLE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\dev\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutilities\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdistributed\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mrank_zero_only\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrank_zero_warn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrank_zero_info\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutilities\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_func\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmove_data_to_device\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutilities\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparsing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mAttributeDict\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\dev\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\apply_func.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mTORCHTEXT_AVAILABLE\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfind_spec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"torchtext\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mTORCHTEXT_AVAILABLE\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m     \u001B[1;32mfrom\u001B[0m \u001B[0mtorchtext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mBatch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0mBatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'Batch' from 'torchtext.data' (C:\\dev\\anaconda3\\lib\\site-packages\\torchtext\\data\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from transforms import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PretrainCIFARDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.picture_ids = None\n",
    "        self.train_dataset = None\n",
    "        self.data_dir = \"datasets\"\n",
    "        self.download = True\n",
    "        self.batch_size = 256\n",
    "        self.num_workers = 5\n",
    "        self.num_labeled_classes = 80\n",
    "        self.num_unlabeled_classes = 20\n",
    "        self.dataset_class = getattr(torchvision.datasets, \"CIFAR100\")\n",
    "        self.transform_train = get_transforms(\"unsupervised\", \"CIFAR100\")\n",
    "        self.transform_val = get_transforms(\"eval\", \"CIFAR100\")\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.picture_ids = [ [] for _ in range(100) ] #np.zeros([100,1])\n",
    "\n",
    "        # train dataset\n",
    "        self.train_dataset = self.dataset_class(\n",
    "            self.data_dir, train=True, transform=self.transform_train, download=self.download\n",
    "        )\n",
    "\n",
    "        for data in self.train_dataset:\n",
    "            self.picture_ids[data[1]].append(data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/7y/b34zlc9j6d1888sf_cfmypbw0000gn/T/ipykernel_8243/1676740687.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mdm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPretrainCIFARDataModule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetup\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/7y/b34zlc9j6d1888sf_cfmypbw0000gn/T/ipykernel_8243/76372230.py\u001B[0m in \u001B[0;36msetup\u001B[0;34m(self, stage)\u001B[0m\n\u001B[1;32m     22\u001B[0m         )\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpicture_ids\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/deep_learning/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 121\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    122\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_transform\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/Master_HPI/3.Semester/PAoDL/padl-22-t-4/src/UNO-main/utils/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/Master_HPI/3.Semester/PAoDL/padl-22-t-4/src/UNO-main/utils/transforms.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/deep_learning/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     62\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/deep_learning/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m     96\u001B[0m             \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mConverted\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m         \"\"\"\n\u001B[0;32m---> 98\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/deep_learning/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001B[0m in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpermute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontiguous\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mByteTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdefault_float_dtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdiv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m255\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dm = PretrainCIFARDataModule()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "40000\n",
      "Files already downloaded and verified\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "labeled_classes = range(80)\n",
    "\n",
    "# train dataset\n",
    "train_dataset = getattr(torchvision.datasets, \"CIFAR100\")(\n",
    "    \"datasets/\", train=True, transform=get_transforms(\"unsupervised\", \"CIFAR100\"), download=True\n",
    ")\n",
    "train_indices_lab = np.where(\n",
    "    np.isin(np.array(train_dataset.targets), labeled_classes)\n",
    ")[0]\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_indices_lab)\n",
    "print(len(train_dataset))\n",
    "\n",
    "# val datasets\n",
    "val_dataset = getattr(torchvision.datasets, \"CIFAR100\")(\n",
    "    \"datasets/\", train=False, transform=get_transforms(\"eval\", \"CIFAR100\"), download=True\n",
    ")\n",
    "val_indices_lab = np.where(np.isin(np.array(val_dataset.targets), labeled_classes))[0]\n",
    "val_dataset = torch.utils.data.Subset(val_dataset, val_indices_lab)\n",
    "print(len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "num_labeled_classes = 80\n",
    "labeled_classes = range(num_labeled_classes)\n",
    "picture_ids_train = [[] for _ in labeled_classes]\n",
    "picture_ids_val = [[] for _ in labeled_classes]\n",
    "\n",
    "# download and load the train dataset\n",
    "train_dataset = getattr(torchvision.datasets, \"CIFAR100\")(\n",
    "    \"datasets/\", train=True, transform=get_transforms(\"unsupervised\", \"CIFAR100\"), download=True\n",
    ")\n",
    "\n",
    "# download and load the val dataset\n",
    "val_dataset = getattr(torchvision.datasets, \"CIFAR100\")(\n",
    "    \"datasets/\", train=False, transform=get_transforms(\"eval\", \"CIFAR100\"), download=True\n",
    ")\n",
    "\n",
    "# take only the indices of the first num_labeled_classes classes\n",
    "train_indices_lab = np.where(\n",
    "     np.isin(np.array(train_dataset.targets), labeled_classes)\n",
    ")[0]\n",
    "\n",
    "# take only the indices of the first num_labeled_classes classes\n",
    "val_indices_lab = np.where(\n",
    "     np.isin(np.array(val_dataset.targets), labeled_classes)\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 480, 460, 442, 424, 407, 391, 375, 360, 346, 332, 319, 306, 294, 282, 271, 260, 249, 239, 230, 221, 212, 203, 195, 187, 180, 172, 166, 159, 153, 146, 141, 135, 129, 124, 119, 115, 110, 105, 101, 97, 93, 90, 86, 82, 79, 76, 73, 70, 67, 64, 62, 59, 57, 55, 52, 50, 48, 46, 44, 43, 41, 39, 38, 36, 35, 33, 32, 31, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19]\n",
      "[100, 96, 92, 88, 84, 81, 78, 75, 72, 69, 66, 63, 61, 58, 56, 54, 52, 49, 47, 46, 44, 42, 40, 39, 37, 36, 34, 33, 31, 30, 29, 28, 27, 25, 24, 23, 23, 22, 21, 20, 19, 18, 18, 17, 16, 15, 15, 14, 14, 13, 12, 12, 11, 11, 11, 10, 10, 9, 9, 8, 8, 8, 7, 7, 7, 7, 6, 6, 6, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 3]\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "train_num_samples_per_class = []\n",
    "val_num_samples_per_class = []\n",
    "\n",
    "# starting from class 0, perform long-tailed sampling by using a decreasing exponential function\n",
    "# the number of samples considered per class is stored as a list\n",
    "for i in range(num_labeled_classes):\n",
    "    train_num_samples_per_class.append(int(500  * (0.96 ** i)))\n",
    "    val_num_samples_per_class.append(int(100  * (0.96 ** i)))\n",
    "\n",
    "print(train_num_samples_per_class)\n",
    "print(val_num_samples_per_class)\n",
    "\n",
    "print(len(train_num_samples_per_class))\n",
    "print(len(val_num_samples_per_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11982\n",
      "2367\n",
      "11982\n",
      "2367\n"
     ]
    }
   ],
   "source": [
    "# since the elements of the train/val dataset variables are not sorted by the numeric value of the class, we first filter each sample by its class yielding always\n",
    "# 500 indices for train and 100 samples for val. Then, the long-tailed sampling is performed by taking only as much samples as the value at position i in train/val_num_samples_per_class\n",
    "# i.e., the first class 0 will have the most samples and the last class will have the least samples\n",
    "# the Subset class is then used to take the corresponding samples from the dataset and at the same time drop the remaining classes from the dataset\n",
    "\n",
    "index_list_final_train = []\n",
    "index_list_final_val = []\n",
    "for i in labeled_classes:\n",
    "\n",
    "    index_list_final_train += np.where(np.isin(np.array(train_dataset.targets), [i]))[0][:train_num_samples_per_class[i]].tolist()\n",
    "    index_list_final_val += np.where(np.isin(np.array(val_dataset.targets), [i]))[0][:val_num_samples_per_class[i]].tolist()\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, index_list_final_train)\n",
    "val_dataset = torch.utils.data.Subset(val_dataset, index_list_final_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}