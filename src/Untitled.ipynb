{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from utils.transforms import get_transforms\n",
    "from utils.transforms import DiscoverTargetTransform\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def get_datamodule(args, mode):\n",
    "    if mode == \"pretrain\":\n",
    "        if args.dataset == \"ImageNet\":\n",
    "            return PretrainImageNetDataModule(args)\n",
    "        else:\n",
    "            return PretrainCIFARDataModule(args)\n",
    "    elif mode == \"discover\":\n",
    "        if args.dataset == \"ImageNet\":\n",
    "            return DiscoverImageNetDataModule(args)\n",
    "        else:\n",
    "            return DiscoverCIFARDataModule(args)\n",
    "\n",
    "\n",
    "class PretrainCIFARDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.data_dir = args.data_dir\n",
    "        self.download = args.download\n",
    "        self.batch_size = args.batch_size\n",
    "        self.num_workers = args.num_workers\n",
    "        self.num_labeled_classes = args.num_labeled_classes\n",
    "        self.num_unlabeled_classes = args.num_unlabeled_classes\n",
    "        self.dataset_class = getattr(torchvision.datasets, args.dataset)\n",
    "        self.transform_train = get_transforms(\"unsupervised\", args.dataset)\n",
    "        self.transform_val = get_transforms(\"eval\", args.dataset)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.dataset_class(self.data_dir, train=True, download=self.download)\n",
    "        self.dataset_class(self.data_dir, train=False, download=self.download)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        picture_ids = [ [] for _ in range(100) ] #np.zeros([100,1])\n",
    "\n",
    "\n",
    "\n",
    "        #REMOVE labeled_classes = range(self.num_labeled_classes)\n",
    "\n",
    "        # train dataset\n",
    "        self.train_dataset = self.dataset_class(\n",
    "            self.data_dir, train=True, transform=self.transform_train\n",
    "        )\n",
    "\n",
    "        for data in self.train_dataset:\n",
    "            picture_ids[data.target].append(data.id)\n",
    "\n",
    "        train_indices_lab = []\n",
    "        val_indices_lab = []\n",
    "\n",
    "        for i in range(100):\n",
    "            l = int( len(picture_ids[i]) * 0.5 * self.g( i ) )\n",
    "            train_indices_lab += picture_ids[i][0:l]\n",
    "            val_indices_lab += picture_ids[i][l:]\n",
    "\n",
    "        # train_indices_lab = np.where(\n",
    "        #     np.isin(np.array(self.train_dataset.targets), labeled_classes)\n",
    "        # )[0]\n",
    "        self.train_dataset = torch.utils.data.Subset(self.train_dataset, train_indices_lab)\n",
    "\n",
    "        # val datasets\n",
    "        self.val_dataset = self.dataset_class(\n",
    "            self.data_dir, train=False, transform=self.transform_val\n",
    "        )\n",
    "            \n",
    "\n",
    "        val_indices_lab = np.where(np.isin(np.array(self.val_dataset.targets), labeled_classes))[0]\n",
    "        self.val_dataset = torch.utils.data.Subset(self.val_dataset, val_indices_lab)\n",
    "\n",
    "    def g(self, i):\n",
    "        return 0.9 ** i\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "\n",
    "class DiscoverCIFARDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.data_dir = args.data_dir\n",
    "        self.download = args.download\n",
    "        self.batch_size = args.batch_size\n",
    "        self.num_workers = args.num_workers\n",
    "        self.num_labeled_classes = args.num_labeled_classes\n",
    "        self.num_unlabeled_classes = args.num_unlabeled_classes\n",
    "        self.dataset_class = getattr(torchvision.datasets, args.dataset)\n",
    "        self.transform_train = get_transforms(\n",
    "            \"unsupervised\",\n",
    "            args.dataset,\n",
    "            multicrop=args.multicrop,\n",
    "            num_large_crops=args.num_large_crops,\n",
    "            num_small_crops=args.num_small_crops,\n",
    "        )\n",
    "        self.transform_val = get_transforms(\"eval\", args.dataset)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.dataset_class(self.data_dir, train=True, download=self.download)\n",
    "        self.dataset_class(self.data_dir, train=False, download=self.download)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        labeled_classes = range(self.num_labeled_classes)\n",
    "        unlabeled_classes = range(\n",
    "            self.num_labeled_classes, self.num_labeled_classes + self.num_unlabeled_classes\n",
    "        )\n",
    "\n",
    "        # train dataset\n",
    "        self.train_dataset = self.dataset_class(\n",
    "            self.data_dir, train=True, transform=self.transform_train\n",
    "        )\n",
    "\n",
    "        # val datasets\n",
    "        val_dataset_train = self.dataset_class(\n",
    "            self.data_dir, train=True, transform=self.transform_val\n",
    "        )\n",
    "        val_dataset_test = self.dataset_class(\n",
    "            self.data_dir, train=False, transform=self.transform_val\n",
    "        )\n",
    "        # unlabeled classes, train set\n",
    "        val_indices_unlab_train = np.where(\n",
    "            np.isin(np.array(val_dataset_train.targets), unlabeled_classes)\n",
    "        )[0]\n",
    "        val_subset_unlab_train = torch.utils.data.Subset(val_dataset_train, val_indices_unlab_train)\n",
    "        # unlabeled classes, test set\n",
    "        val_indices_unlab_test = np.where(\n",
    "            np.isin(np.array(val_dataset_test.targets), unlabeled_classes)\n",
    "        )[0]\n",
    "        val_subset_unlab_test = torch.utils.data.Subset(val_dataset_test, val_indices_unlab_test)\n",
    "        # labeled classes, test set\n",
    "        val_indices_lab_test = np.where(\n",
    "            np.isin(np.array(val_dataset_test.targets), labeled_classes)\n",
    "        )[0]\n",
    "        val_subset_lab_test = torch.utils.data.Subset(val_dataset_test, val_indices_lab_test)\n",
    "\n",
    "        self.val_datasets = [val_subset_unlab_train, val_subset_unlab_test, val_subset_lab_test]\n",
    "\n",
    "    @property\n",
    "    def dataloader_mapping(self):\n",
    "        return {0: \"unlab/train\", 1: \"unlab/test\", 2: \"lab/test\"}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return [\n",
    "            torch.utils.data.DataLoader(\n",
    "                dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "            )\n",
    "            for dataset in self.val_datasets\n",
    "        ]\n",
    "\n",
    "\n",
    "IMAGENET_CLASSES_118 = [\n",
    "    \"n01498041\",\n",
    "    \"n01537544\",\n",
    "    \"n01580077\",\n",
    "    \"n01592084\",\n",
    "    \"n01632777\",\n",
    "    \"n01644373\",\n",
    "    \"n01665541\",\n",
    "    \"n01675722\",\n",
    "    \"n01688243\",\n",
    "    \"n01729977\",\n",
    "    \"n01775062\",\n",
    "    \"n01818515\",\n",
    "    \"n01843383\",\n",
    "    \"n01883070\",\n",
    "    \"n01950731\",\n",
    "    \"n02002724\",\n",
    "    \"n02013706\",\n",
    "    \"n02092339\",\n",
    "    \"n02093256\",\n",
    "    \"n02095314\",\n",
    "    \"n02097130\",\n",
    "    \"n02097298\",\n",
    "    \"n02098413\",\n",
    "    \"n02101388\",\n",
    "    \"n02106382\",\n",
    "    \"n02108089\",\n",
    "    \"n02110063\",\n",
    "    \"n02111129\",\n",
    "    \"n02111500\",\n",
    "    \"n02112350\",\n",
    "    \"n02115913\",\n",
    "    \"n02117135\",\n",
    "    \"n02120505\",\n",
    "    \"n02123045\",\n",
    "    \"n02125311\",\n",
    "    \"n02134084\",\n",
    "    \"n02167151\",\n",
    "    \"n02190166\",\n",
    "    \"n02206856\",\n",
    "    \"n02231487\",\n",
    "    \"n02256656\",\n",
    "    \"n02398521\",\n",
    "    \"n02480855\",\n",
    "    \"n02481823\",\n",
    "    \"n02490219\",\n",
    "    \"n02607072\",\n",
    "    \"n02666196\",\n",
    "    \"n02672831\",\n",
    "    \"n02704792\",\n",
    "    \"n02708093\",\n",
    "    \"n02814533\",\n",
    "    \"n02817516\",\n",
    "    \"n02840245\",\n",
    "    \"n02843684\",\n",
    "    \"n02870880\",\n",
    "    \"n02877765\",\n",
    "    \"n02966193\",\n",
    "    \"n03016953\",\n",
    "    \"n03017168\",\n",
    "    \"n03026506\",\n",
    "    \"n03047690\",\n",
    "    \"n03095699\",\n",
    "    \"n03134739\",\n",
    "    \"n03179701\",\n",
    "    \"n03255030\",\n",
    "    \"n03388183\",\n",
    "    \"n03394916\",\n",
    "    \"n03424325\",\n",
    "    \"n03467068\",\n",
    "    \"n03476684\",\n",
    "    \"n03483316\",\n",
    "    \"n03627232\",\n",
    "    \"n03658185\",\n",
    "    \"n03710193\",\n",
    "    \"n03721384\",\n",
    "    \"n03733131\",\n",
    "    \"n03785016\",\n",
    "    \"n03786901\",\n",
    "    \"n03792972\",\n",
    "    \"n03794056\",\n",
    "    \"n03832673\",\n",
    "    \"n03843555\",\n",
    "    \"n03877472\",\n",
    "    \"n03899768\",\n",
    "    \"n03930313\",\n",
    "    \"n03935335\",\n",
    "    \"n03954731\",\n",
    "    \"n03995372\",\n",
    "    \"n04004767\",\n",
    "    \"n04037443\",\n",
    "    \"n04065272\",\n",
    "    \"n04069434\",\n",
    "    \"n04090263\",\n",
    "    \"n04118538\",\n",
    "    \"n04120489\",\n",
    "    \"n04141975\",\n",
    "    \"n04152593\",\n",
    "    \"n04154565\",\n",
    "    \"n04204347\",\n",
    "    \"n04208210\",\n",
    "    \"n04209133\",\n",
    "    \"n04258138\",\n",
    "    \"n04311004\",\n",
    "    \"n04326547\",\n",
    "    \"n04367480\",\n",
    "    \"n04447861\",\n",
    "    \"n04483307\",\n",
    "    \"n04522168\",\n",
    "    \"n04548280\",\n",
    "    \"n04554684\",\n",
    "    \"n04597913\",\n",
    "    \"n04612504\",\n",
    "    \"n07695742\",\n",
    "    \"n07697313\",\n",
    "    \"n07697537\",\n",
    "    \"n07716906\",\n",
    "    \"n12998815\",\n",
    "    \"n13133613\",\n",
    "]\n",
    "\n",
    "IMAGENET_CLASSES_30 = {\n",
    "    \"A\": [\n",
    "        \"n01580077\",\n",
    "        \"n01688243\",\n",
    "        \"n01883070\",\n",
    "        \"n02092339\",\n",
    "        \"n02095314\",\n",
    "        \"n02098413\",\n",
    "        \"n02108089\",\n",
    "        \"n02120505\",\n",
    "        \"n02123045\",\n",
    "        \"n02256656\",\n",
    "        \"n02607072\",\n",
    "        \"n02814533\",\n",
    "        \"n02840245\",\n",
    "        \"n02843684\",\n",
    "        \"n02877765\",\n",
    "        \"n03179701\",\n",
    "        \"n03424325\",\n",
    "        \"n03483316\",\n",
    "        \"n03627232\",\n",
    "        \"n03658185\",\n",
    "        \"n03785016\",\n",
    "        \"n03794056\",\n",
    "        \"n03899768\",\n",
    "        \"n04037443\",\n",
    "        \"n04069434\",\n",
    "        \"n04118538\",\n",
    "        \"n04154565\",\n",
    "        \"n04311004\",\n",
    "        \"n04522168\",\n",
    "        \"n07695742\",\n",
    "    ],\n",
    "    \"B\": [\n",
    "        \"n01883070\",\n",
    "        \"n02013706\",\n",
    "        \"n02093256\",\n",
    "        \"n02097130\",\n",
    "        \"n02101388\",\n",
    "        \"n02106382\",\n",
    "        \"n02112350\",\n",
    "        \"n02167151\",\n",
    "        \"n02490219\",\n",
    "        \"n02814533\",\n",
    "        \"n02843684\",\n",
    "        \"n02870880\",\n",
    "        \"n03017168\",\n",
    "        \"n03047690\",\n",
    "        \"n03134739\",\n",
    "        \"n03394916\",\n",
    "        \"n03424325\",\n",
    "        \"n03483316\",\n",
    "        \"n03658185\",\n",
    "        \"n03721384\",\n",
    "        \"n03733131\",\n",
    "        \"n03786901\",\n",
    "        \"n03843555\",\n",
    "        \"n04120489\",\n",
    "        \"n04152593\",\n",
    "        \"n04208210\",\n",
    "        \"n04258138\",\n",
    "        \"n04522168\",\n",
    "        \"n04554684\",\n",
    "        \"n12998815\",\n",
    "    ],\n",
    "    \"C\": [\n",
    "        \"n01580077\",\n",
    "        \"n01592084\",\n",
    "        \"n01632777\",\n",
    "        \"n01775062\",\n",
    "        \"n01818515\",\n",
    "        \"n02097130\",\n",
    "        \"n02097298\",\n",
    "        \"n02098413\",\n",
    "        \"n02111500\",\n",
    "        \"n02115913\",\n",
    "        \"n02117135\",\n",
    "        \"n02398521\",\n",
    "        \"n02480855\",\n",
    "        \"n02817516\",\n",
    "        \"n02843684\",\n",
    "        \"n02877765\",\n",
    "        \"n02966193\",\n",
    "        \"n03095699\",\n",
    "        \"n03394916\",\n",
    "        \"n03424325\",\n",
    "        \"n03710193\",\n",
    "        \"n03733131\",\n",
    "        \"n03785016\",\n",
    "        \"n03995372\",\n",
    "        \"n04090263\",\n",
    "        \"n04120489\",\n",
    "        \"n04326547\",\n",
    "        \"n04522168\",\n",
    "        \"n07697537\",\n",
    "        \"n07716906\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "class DiscoverDataset:\n",
    "    def __init__(self, labeled_dataset, unlabeled_dataset):\n",
    "        self.labeled_dataset = labeled_dataset\n",
    "        self.unlabeled_dataset = unlabeled_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return max([len(self.labeled_dataset), len(self.unlabeled_dataset)])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        labeled_index = index % len(self.labeled_dataset)\n",
    "        labeled_data = self.labeled_dataset[labeled_index]\n",
    "        unlabeled_index = index % len(self.unlabeled_dataset)\n",
    "        unlabeled_data = self.unlabeled_dataset[unlabeled_index]\n",
    "        return (*labeled_data, *unlabeled_data)\n",
    "\n",
    "\n",
    "class DiscoverImageNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.data_dir = args.data_dir\n",
    "        self.batch_size = args.batch_size\n",
    "        self.num_workers = args.num_workers\n",
    "        self.imagenet_split = args.imagenet_split\n",
    "        self.dataset_class = torchvision.datasets.ImageFolder\n",
    "        self.transform_train = get_transforms(\n",
    "            \"unsupervised\",\n",
    "            args.dataset,\n",
    "            multicrop=args.multicrop,\n",
    "            num_large_crops=args.num_large_crops,\n",
    "            num_small_crops=args.num_small_crops,\n",
    "        )\n",
    "        self.transform_val = get_transforms(\"eval\", args.dataset)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_data_dir = os.path.join(self.data_dir, \"train\")\n",
    "        val_data_dir = os.path.join(self.data_dir, \"val\")\n",
    "\n",
    "        # train dataset\n",
    "        train_dataset = self.dataset_class(train_data_dir, transform=self.transform_train)\n",
    "\n",
    "        # split classes\n",
    "        mapping = {c[:9]: i for c, i in train_dataset.class_to_idx.items()}\n",
    "        labeled_classes = list(set(mapping.keys()) - set(IMAGENET_CLASSES_118))\n",
    "        labeled_classes.sort()\n",
    "        labeled_class_idxs = [mapping[c] for c in labeled_classes]\n",
    "        unlabeled_classes = IMAGENET_CLASSES_30[self.imagenet_split]\n",
    "        unlabeled_classes.sort()\n",
    "        unlabeled_class_idxs = [mapping[c] for c in unlabeled_classes]\n",
    "\n",
    "        # target transform\n",
    "        all_classes = labeled_classes + unlabeled_classes\n",
    "        target_transform = DiscoverTargetTransform(\n",
    "            {mapping[c]: i for i, c in enumerate(all_classes)}\n",
    "        )\n",
    "        train_dataset.target_transform = target_transform\n",
    "\n",
    "        # train set\n",
    "        targets = np.array([img[1] for img in train_dataset.imgs])\n",
    "        labeled_idxs = np.where(np.isin(targets, np.array(labeled_class_idxs)))[0]\n",
    "        labeled_subset = torch.utils.data.Subset(train_dataset, labeled_idxs)\n",
    "        unlabeled_idxs = np.where(np.isin(targets, np.array(unlabeled_class_idxs)))[0]\n",
    "        unlabeled_subset = torch.utils.data.Subset(train_dataset, unlabeled_idxs)\n",
    "        self.train_dataset = DiscoverDataset(labeled_subset, unlabeled_subset)\n",
    "\n",
    "        # val datasets\n",
    "        val_dataset_train = self.dataset_class(\n",
    "            train_data_dir, transform=self.transform_val, target_transform=target_transform\n",
    "        )\n",
    "        val_dataset_test = self.dataset_class(\n",
    "            val_data_dir, transform=self.transform_val, target_transform=target_transform\n",
    "        )\n",
    "        targets_train = np.array([img[1] for img in val_dataset_train.imgs])\n",
    "        targets_test = np.array([img[1] for img in val_dataset_test.imgs])\n",
    "        # unlabeled classes, train set\n",
    "        unlabeled_idxs = np.where(np.isin(targets_train, np.array(unlabeled_class_idxs)))[0]\n",
    "        unlabeled_subset_train = torch.utils.data.Subset(val_dataset_train, unlabeled_idxs)\n",
    "        # unlabeled classes, test set\n",
    "        unlabeled_idxs = np.where(np.isin(targets_test, np.array(unlabeled_class_idxs)))[0]\n",
    "        unlabeled_subset_test = torch.utils.data.Subset(val_dataset_test, unlabeled_idxs)\n",
    "        # labeled classes, test set\n",
    "        labeled_idxs = np.where(np.isin(targets_test, np.array(labeled_class_idxs)))[0]\n",
    "        labeled_subset_test = torch.utils.data.Subset(val_dataset_test, labeled_idxs)\n",
    "\n",
    "        self.val_datasets = [unlabeled_subset_train, unlabeled_subset_test, labeled_subset_test]\n",
    "\n",
    "    @property\n",
    "    def dataloader_mapping(self):\n",
    "        return {0: \"unlab/train\", 1: \"unlab/test\", 2: \"lab/test\"}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size // 2,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return [\n",
    "            torch.utils.data.DataLoader(\n",
    "                dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=True,\n",
    "                drop_last=False,\n",
    "            )\n",
    "            for dataset in self.val_datasets\n",
    "        ]\n",
    "\n",
    "\n",
    "class PretrainImageNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.data_dir = args.data_dir\n",
    "        self.batch_size = args.batch_size\n",
    "        self.num_workers = args.num_workers\n",
    "        self.dataset_class = torchvision.datasets.ImageFolder\n",
    "        self.transform_train = get_transforms(\"unsupervised\", args.dataset)\n",
    "        self.transform_val = get_transforms(\"eval\", args.dataset)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_data_dir = os.path.join(self.data_dir, \"train\")\n",
    "        val_data_dir = os.path.join(self.data_dir, \"val\")\n",
    "\n",
    "        # train dataset\n",
    "        train_dataset = self.dataset_class(train_data_dir, transform=self.transform_train)\n",
    "\n",
    "        # find labeled classes\n",
    "        mapping = {c[:9]: i for c, i in train_dataset.class_to_idx.items()}\n",
    "        labeled_classes = list(set(mapping.keys()) - set(IMAGENET_CLASSES_118))\n",
    "        labeled_classes.sort()\n",
    "        labeled_class_idxs = [mapping[c] for c in labeled_classes]\n",
    "\n",
    "        # target transform\n",
    "        target_transform = DiscoverTargetTransform(\n",
    "            {mapping[c]: i for i, c in enumerate(labeled_classes)}\n",
    "        )\n",
    "        train_dataset.target_transform = target_transform\n",
    "\n",
    "        # train set\n",
    "        targets = np.array([img[1] for img in train_dataset.imgs])\n",
    "        labeled_idxs = np.where(np.isin(targets, np.array(labeled_class_idxs)))[0]\n",
    "        self.train_dataset = torch.utils.data.Subset(train_dataset, labeled_idxs)\n",
    "\n",
    "        # val datasets\n",
    "        val_dataset = self.dataset_class(\n",
    "            val_data_dir, transform=self.transform_val, target_transform=target_transform\n",
    "        )\n",
    "        targets = np.array([img[1] for img in val_dataset.imgs])\n",
    "        # labeled classes, test set\n",
    "        labeled_idxs = np.where(np.isin(targets, np.array(labeled_class_idxs)))[0]\n",
    "        self.val_dataset = torch.utils.data.Subset(val_dataset, labeled_idxs)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
